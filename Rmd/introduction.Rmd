---
title: "Introduction to the teaching method"
---

```{r seed, cache=FALSE, echo=FALSE}
set.seed(1234)
```

# Objectives

The aim of this session is to introduce both the concepts that will be used throughout the course as well as the teaching philosophy that it will follow.
Throughout the course your learning will proceed in 4 steps:

1. **simulation** to get an understanding of the process that we typically assume to generate observed infectious disease data
2. **initial estimation** using standard R tools (especially the `optim()` function) as a way to link the simulation process to observations
3. **full estimation** using the statistical programming language [stan](https://mc-stan.org/) as a way to obtain a range of flexible estimates with uncertainty 
4. **open-source tools** that implement the methods encountered and allow you to avoid having to write your own models.

We will illustrate this approach using a simple non-epidemiological example before moving on to infectious diseases in the next session.
We will investigate a scenario where we're observing coin flips but we don't know if the coin is biased towards one side or the other.

# Simulating coin flips

Flipping a coin with a given probability $p$ of landing on a given side is also called a Bernoulli trial, and the corresponding probability distribution is the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) with probability mass function given by

$$
f(s;p)=\left{
\begin{cases}
  p {\text{if }}s=1,\\
  q=1-p {\text{if }}s=0.\\
end{cases}
$$

where $s=1$ for the side that has probability $p$, and $k=0$ for the other side.
We will call $s=1$ "heads" and $s=0$ "tails".

If this procedure is repeated $n$ times, the probability of observing heads $k$ times is given by the [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution) with probability mass function 

$$
f(k|n,p)={\binom {n}{k}}p^{k}(1-p)^{n-k}}.
$$

In R, we can generate random numbers from this distribution using the `rbinom()` command.
To simulate 25 coin flips where the probability of getting heads is 0.4 you can write

```{r}
k_heads <- rbinom(n = 1, size = 25, p = 0.4)
```

Note that in `rbinom()` the argument `n` refers to the number of repetitions (of the 25 coin flips), not the number of flips as above, which is given by `size`.

# Initial estimation of coin bias
 
In [statistical inference](https://en.wikipedia.org/wiki/Statistical_inference) we are dealing with the inverse problem to the one described above:
Rather than describing the outcomes of a given process, we try to learn something about the world by observing outcomes and making assumptions about the process.
In order to do so, we need to link the model to observations, and this is commonly done using the _likelihood function_.
This describes the probability of observing the data given a set of parameters in our model:

$$
\mathcal {L} (p \mid \mathrm{Data})= \mathcal {L} (p \mid k, n) = f(k| n, p)
$$

In other words, for a given $n$ (total number of coin flips) the likelihood (which is a function of $p$) is described by the same function as the probability of observing $k$ heads given $p$.

To get an initial estimate of coin bias, we can use the `optim()` function to find the $p$ that maximises the likelihood.
As is common practice, we take the logarithm and maximise the log-likelihood, which gives the same result as maximising the likelihood (because the logarithm is a monotonic function) but makes it easier for a computer to deal with small numbers.

```{r}
## log-likelihood function
ll <- function(p, k, n) {
  dbinom(x = k, size = n, p = p, log = TRUE)
}
p_est <- optimize(
  f = ll, lower = 0, upper = 1, n = 25, k = k_heads, maximum = TRUE
)
p_est
```

The `maximum` is the estimated bias, or the coin probability of flipping heads: `r round(p_est$maximum, 2)`.
Of course we could have simply calculated this as `k_heads / 25` but in the more complex problems we'll encounter in the following sessions we won't always be able to do this.


# Full estimate of coin bias
 
We will now turn to a "full" estimate of the coin bias, one that will give us a probability of the coin having a certain bias, rather than only the probability of observing the data given a coin of a certain bias.
We will do this using Bayesian inference using [stan](https://mc-stan.org/), a "state-of-the-art platform for statistical modeling and high-performance statistical computation" to generate samples from the _posterior distribution_, which represents the probability of parameters given prior knowledge and data.
This is the inverse of simulation, where we draw samples of data given parameters.

Using _stan_ may seem a bit over the top for estimating bias from a few coin flips, but it will come in handy later when we look at more complicated problems.
In order to conduct Bayesian inference, we will need to specify a [prior probability distribution](https://en.wikipedia.org/wiki/Prior_probability) for our parameter $p$ that reflects what we believe about the coin before we confront it with data.

Let us assume we are completely ignorant, i.e. $p$ is equally likely to be any value between 0 and 1.
In that case, we can use a _uniform prior_ bounded by 0 and 1, or in mathematical notation

$$
p \sim \mathcal{U}(0, 1)
$$

This is just another way of saying that any value of $p$ between 0 and 1 has the same _prior probability density_.

When doing statistical inference we're often better off using distributions that don't have sharp edges like the uniform distribution.
In our case here we could use, for example, a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) which is also bounded by 0 and 1 but tapers of smoothly towards the edges.

_Stan_ is a so-called probabilistic programming language.
This means that we write down the all the statistical relationships between variables in our model and then can use it to conduct inference on our desired parameters.

In order to do our estimate of coin bias as above, we could write the following model in stan:

```{r}
coin_model <- '

  data {
    int trials;
    int heads;
  }

  parameters {
     real<lower = 0, upper = 1> prob_heads;
  } 

  model {
    prob_heads ~ beta(5, 5);
    heads ~ binomial(trials, prob_heads);
  }
'
```

In this model, we have defined three sections:
- `data` represents all the things that aren't estimated, i.e. the things before the bar (|) in the likelihood function
- `parameters` are the things that are estimated
- `model` defines the prior and likelihood

In order to conduct inference, we use the `sampling()` function in the `rstan` package

```{r}
library("rstan")
model <- stan_model(model_code = coin_model) ## this may take a little while
stan_result <- sampling(model, data = list(trials = 25, heads = k_heads))
```

We can inspect the results using

```{r}
stan_result
```

**Take 15 minutes*** to experiment with the code above: how does the error of the estimate change with the number of trials, or the given `k_heads`.
Does the result match what you would expect?
You could change the prior distribution for the bias to a uniform distribution by changing the `beta` distribution above to a `uniform(lower_bound, upper_bound)` (replacing `lower_bound` and `upper_bound` with the appropriate parameters). 
Does this change your results?

# Open-source tools

the [fitdistrplus](https://lbbe-software.github.io/fitdistrplus/) package implements a wide range of probability distributions that can be fitted to data.

**Take 15 minutes** to install the `fitdistrplus` package and look at its documentation. 
Can you reproduce the result we obtained using `stan` above?

# Going further

If you have time, you could try to experiment with the stan code above.
For example, you could specify a stronger prior on `prob_heads` if your assumption is that the coin is more or less fair.
Or you could look at having a number of coins and test whether they are, on average, fair.

# References

---
title: "Delay distributions"
order: 2
---

[Introduction to epidemiological delays](slides/introduction-to-epidemiological-delays.qmd)

```{r echo = FALSE}
set.seed(123)
```

## Objectives

The aim of this session is for you to familiarise yourself with the concept of delay distributions used to describe reporting in infectious disease epidemiology.
First we'll look at this working forwards from infections - we'll use `R` to simulate delays in the reporting of cases in an infectious disease outbreak, before using the simulation model in stan to estimate delays from a data set of outcomes.

## Libraries used

In this session we will use the `nfidd` package to load a data set of infection times, the `ggplot2` package for plotting, the `dplyr` and `tidyr` packages to wrangle data, the `lubridate` package to deal with dates, the `here` package to find the stan models, the `cmdstanr` package for using stan, and the `posterior` packages for investigating the results of the inference conducted with stan.

```{r libraries, message = FALSE}
library("nfidd")
library("ggplot2")
library("dplyr")
library("tidyr")
library("lubridate")
library("here")
library("cmdstanr")
library("posterior")
```

::: {.callout-tip}
The best way to interact with the material is via the [Visual Editor](https://docs.posit.co/ide/user/ide/guide/documents/visual-editor.html) of RStudio.
If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the `here()` commands below find the stan model files.
:::

## Simulating delayed epidemiological data

We will start this session by working with a simulated data set of infections from a disease that has caused an outbreak which subsequently ended.
In our example outbreak, there were 649 infections.
The outbreak lasted around 90 days after the first infection, with new infections peaking roughly around day 40.

::: callout-note
For now we will not concern ourselves with the model used to generate the epidemic.
This represents a typical situation in the real world, where we may have a model of how an infection has spread, but we don't necessarily know how well this corresponds to what really happened.
:::

We will later deal with modelling the infectious process.
For now, we will focus on modelling how infections get reported in data - the *observation* process.
Using infectious disease data for analysis comes with three common challenges:

1.  We don't normally observe infections directly, but their *outcomes* as symptomatic cases, hospitalisations or other realisations.
2.  These observations are *incomplete* (e.g. not every infection leads to hospitalisation, and so focusing on hospitalisations will leave infections unobserved).
3.  These observations happen with a *delay* after the infection occurs (e.g. from infection to symptoms).

### Load the outbreak data

We will work with a data set that is included in the `nfidd` R package that you installed initially.
The column `infection_time` is a linelist of infections from our example outbreak, given as a decimal number of days that have passed since the initial infection of the outbreak.
It can be loaded with the `data` command.

```{r}
data(infection_times)
head(infection_times)

### visualise the infection curve
ggplot(infection_times, aes(x = infection_time)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(n.breaks = 30, expand = c(0, 0)) +
  labs(x = "Infection time (in days)", y = "Number of infections",
       title = "Infections during an outbreak")
```

::: callout-note
In reality, data from an outbreak will usually be given as dates, not decimals; and those will usually not represent infection, but an observed outcome such as symptom onset or hospital admission.
For now we don't want to spend too much time manipulating dates in R, but we will get back to working with more realistic outbreak data later.
:::

### Working forwards: creating a sequence of delays after infection

We would now like to simulate hospitalisations arising from this outbreak.
We will start with our data on infection times, and work forwards to symptom onsets and then hospitalisations. We'll make the following assumptions about the process from infection to hospital admission:

-   Infection to symptoms:
    -   We'll assume all infections cause symptoms.
    -   *Time from infection to symptom onset (incubation period):* We assume that the incubation period is **gamma**-distributed with **shape 5** and **rate 1**, i.e. a mean of 5 days.

-   Symptoms to hospital admission:
    -   We'll assume that 30% of symptomatic cases become hospitalised.
    -   *Time from symptom onset to hospital admission*: We assume that the onset-to-hospitalisation period is **lognormally** distributed, with **meanlog 1.75** and **sdlog 0.5**, corresponding to a mean delay of about a week.

Let's put these assumptions into practice by simulating some data, adding onset and hospitalisation times (in decimal number of days after the first infection) to the infection times. We'll use random values for each infection from the probability distributions we've assumed above.

```{r inf_hosp_solution, file = here::here("snippets", "onset-hosp.r")}
```

Now we can plot infections, hospitalisations and onsets.

```{r plot_distributions, messages = FALSE}
# convert our data frame to long format
dfl <- df |>
  pivot_longer(
    cols = c(infection_time, onset_time, hosp_time),
    names_to = "type", values_to = "time"
  )
# plot
ggplot(dfl, aes(x = time)) +
  geom_histogram(position = "dodge", binwidth = 1) +
  facet_wrap(~ type, ncol = 1) +
  xlab("Time (in days)") +
  ylab("Count")
```

## Working backwards: estimating delay distributions from outcome data

As mentioned above, our data set of infection, symptom onset and hospitalisation times is not the typical data set we encounter in outbreaks.
In reality, we don't have infection dates, and we also have to deal with missing data, incomplete observations, data entry errors etc.
For now, let us just assume we have a data set only including symptom onset times and some hospitalisation times. 

Let's look at a specific problem: we would like to estimate how long it takes for people to become hospitalised after becoming symptomatic.
This might be an important delay to know about, for example when modelling and forecasting hospitalisations, or more generally for estimating required hospital capacity.

To do this we can use our data with *stan* to model the delay from symptom onset to hospitalisation, with the same assumption that it follows a lognormal distribution.

```{r naive_delay_model}
mod <- cmdstan_model(here("stan", "lognormal.stan"))
mod
```

Let's estimate the onset-to-hospitalisation delay using the simulated data set we created above. Do we recover the parameters used for simulation?

We can do this by *sampling* from the model's posterior distribution by feeding it our simulated data set.

```{r sample_naive_delay_model, results = 'hide', message = FALSE, warning = FALSE}
## Specify the time from onset to hospitalisation
df_onset_to_hosp <- df |>
  mutate(onset_to_hosp = hosp_time - onset_time) |> 
  # exclude infections that didn't result in hospitalisation
  drop_na(onset_to_hosp)
## Use the data to sample from the model posterior
res <- mod$sample(
  data = list(
    n = nrow(df_onset_to_hosp),
    y = df_onset_to_hosp$onset_to_hosp
  ),
  refresh = 0, show_exceptions = FALSE, show_messages = FALSE
)
```

::: callout-caution
### Reduce the amount of messages printed to the screen

As before, the arguments to `mod$sample()` after the `data` argument are there to remove the amount of messages printed to the screen (and in this document).
You can safely remove them.
:::

To see the estimates, we can use:

```{r summarise_naive_delay_model}
res$summary()
```

These estimates should look similar to what we used in the simulations.
We can plot the resulting probability density functions.

```{r plot_onset_hospitalisation}
## get shape and rate samples from the posterior
res_df <- res |>
  as_draws_df() |>
  filter(.draw %in% sample(.draw, 20)) ## sample 20 iterations randomly

## find the value (x) that includes 99% of the cumulative density
max_x <- max(qlnorm(0.99, meanlog = res_df$meanlog, sdlog = res_df$sdlog))

## calculate density on grid of x values
x <- seq(0, max_x, length.out = 100)
res_df <- res_df |>
  crossing(x = x) |> ## add grid to data frame
  mutate(density = dlnorm(x, meanlog, sdlog))

## plot
ggplot(res_df, aes(x = x, y = density, group = .draw)) +
  geom_line(alpha = 0.3)
```

## Going further

-   In this session we were in the enviable situation of knowing which distribution was used to generate the data. With real data, of course, we don't have this information available. Try using a different distribution for inference (e.g. normal, or gamma). Do you get a good fit?

## Wrap up

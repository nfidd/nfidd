---
title: "Session 4: Using delay distributions to model the data generating process"
---

```{r echo = FALSE}
set.seed(123)
```

# Objectives

The aim of this session is to introduce how delay distributions can be used to model the population-level data generating process of an epidemic.

# Libraries used

In this session we will use the `nfidd` package to load the data set of infection times, the `dplyr` and `tidyr` packages for data wrangling, the `lubridate` package to handle dates, `ggplot2` library for plotting, the `here` library to find the stan model, and the `cmdstanr` library for using stan.
We will also use the `tidybayes` package for extracting results of the inference.

```{r libraries, message = FALSE}
library("nfidd")
library("dplyr")
library("tidyr")
library("lubridate")
library("ggplot2")
library("here")
library("cmdstanr")
library("tidybayes")
```

::: {.callout-tip}
The code in this session can be run as an interactive notebook using RStudio, or copied-and-pasted into an R session.
It needs to be run inside the course repository so that the `here()` commands below find the stan model files.
:::

# Simulating observations from a time series of infections

As above we first simulate the process that generates the data, before using the same model to conduct inference.

## Delay distributions and convolutions

In the last session we simulated _individual outcomes_ from a delay distribution, and then re-estimated the corresponding parameters.
However, sometimes we do not have data on these individual-level outcomes, either because they are not recorded or because they cannot be shared, for example due to privacy concerns.
At the population level, individual level delays translate into _convolutions_.
If we have a time series of infections $I_t$ ($t=1, 2, 3, \ldots, t_\mathrm{max}$), where $t$ denotes the day on which the infections occur, and observable outcomes occur with a delay given by a delay distribution $p_i$ ($i=0, 1, 2, \dots, p_\mathrm{max}$), where $i$ is the number of days after infection that the observation happens, then the number of observable outcomes $C_t$ on day $t$ is given by

$$
C_t = \sum_{i=0}^{i=p_\mathrm{max}} I_{t-i} p_i
$$

In words, to get the number of observable outcomes on day $t$ is given by the sum of infections on all previous days multiplied by the probability that those infections are observed on day $t$.
For example, the observable outcomes $C_t$ could be the number of symptom onsets on day $t$ and $p_i$ is the incubation period.

We can use exactly the same data as in the previous session but this time aggregate it into a time series:

```{r aggregate}
data(infection_times)
## assume a start date, e.g. 10 May of this year
start_date <- ymd("2024-05-10")
df <- infection_times |>
  mutate(
    incubation_period = rgamma(n(), shape = 5, rate = 1),
    infection_date = floor_date(start_date + infection_time, unit = "day"),
    onset_date = floor_date(
      start_date + infection_time + incubation_period,
      unit = "day"
    ),
  )
## infection time series
inf_time_series <- df |>
  count(infection_date)
head(inf_time_series)
```

The resulting time series does contain any days with no infections.
We can make our calculations easier by adding them:

```{r missing_to_zero}
all_dates <- expand(
  df, infection_date = seq(min(infection_date), max(infection_date), by = "day")
)
inf_time_series <- all_dates |>
  full_join(inf_time_series, by = join_by(infection_date)) |>
  replace_na(list(n = 0))
head(inf_time_series)
```

Now we can convolve the time series with a delay distribution of outcomes to get a time series of outcomes as suggested above.
However, if we want to use the gamma distribution with shape 5 and rate 1 as before we face a problem.
The gamma distribution is a _continuous_ distribution but days are _discrete_ entities.
One solution to this problem is to first _discretise_ the gamma distribution.
To do so we integrate it over 2-day windows, which will give a reasonable approximation to using the continuous distribution with continuous infection times and continuous outcomes.

```{r discretise_2_day_window}
## function that takes two inputs to discretise a continuous delay distribution:
## cdf: a function that defines the CDF (cumulative distribution function) of
## the continuous delay distiribution
## max: the maximum delay
## ...: parameters of the delay distribution
## the function returns a vector of probabilities, corresponding to discrete
## indices 0, 1, 2 of the discretised delay distribution
## example: discretise(pgamma, 14, shape = 5, rate = 1)
discretise <- function(cdf, max, ...) {
  ret <- numeric(max + 1) ## set up vector of size (max + 1)
  ## for the first element we integrate over [0, 1) because delays cannot be
  ## negative
  ret[1] <- cdf(1, ...)
  ## for all other elements we use 2-day integration windows
  ret[2:length(ret)] <- cdf(2:(max + 1), ...) - cdf(0:(max - 1), ...)
  ## normalise
  ret <- ret / sum(ret)
  return(ret)
}
```

::: {.callout-note}
## Take 5 minutes
Try to understand the `discretise()` function above.
Try it with a few different probability distributions and parameters, e.g. for the parameters given above and a maximum of 2 weeks (14 days) it would be:
```{r discretised_gamma}
gamma_pdf <- discretise(pgamma, 14, shape = 5, rate = 1)
gamma_pdf
```
:::

Next we apply a convolution with the discretised incubation period distribution to the time series of infections to generate a time series of symptom onsets.

```{r convolution}
## for each infection date, apply convolution with `gamma_pdf`
onsets <- lapply(seq_len(nrow(inf_time_series)), \(x) {
  ## get vector of infections (14-day window)
  first_index <- max(1, x - 14)
  inf <- inf_time_series$n[seq(first_index, x)]
  ## shorten pdf if needed
  pdf <- gamma_pdf[seq_len(length(inf))]
  ## convolve with delay distribution
  onsets <- round(sum(inf * rev(pdf)))
  data.frame(onset_date = inf_time_series$infection_date[x], onsets = onsets)
})
onsets <- bind_rows(onsets)
```

::: {.callout-tip}
## Take 5 minutes
Try to understand the code above and how it corresponds to the convolution introduced above.

:::

We can plot these symptom onsets
```{r convolution_plot}
ggplot(onsets, aes(x = onset_date, y = onsets)) +
  geom_bar(stat = "identity")
```

Do they look similar to the plot of symptom onsets in the previous session?

## Observation uncertainty

Usually not all data are perfectly observed.
The counting process itself generally introduces a natural form of error that we can, once again, model with a probability distribution.
For modelling counts, a common choice is the Poisson distribution.
We can use this to generate uncertainty around our convolved data.

```{r uncertain}
onsets <- onsets |>
  mutate(observed = rpois(n(), onsets))
```

Does a plot of these observations look more like the data from the previous session than the convolution plotted above?

# Estimating a time series of infection

We now invert the procedure of above, i.e. instead of convolving infects and adding uncertainty to simulate observed symptom onsets, we start with observed simulated onsets to estimate the number of infections, given an incubation period.
Mathematically this amounts to a _deconvolution_ of the time series, i.e. the reverse process to convolution.

```{r stan_deconvolve}
mod <- cmdstan_model(
  here(
    "sessions",
    paste0(
      "04-using-delay-distributions-to-model-the-data-generating-process-of-",
      "an-epidemic"
    ),
    "estimate_infections.stan"
  )
)
mod$print(line_numbers = TRUE)
```

::: {.callout-tip}
## Take 10 minutes
Familarise yourself with the model above.
Unlike before there is now a `functions` block at the beginning of the model (lines 1-33), where we define two functions, `discretise_gamma()` (line 2) and `convolve_with_delay()` (line 18).
These correspond to our earlier **R** function `discretise()` and the code we used to generate a time series of symptom onsets, respectively.
Later, these functions are called in the `model` block, to generate a discretised probability mass function of the gamma distribution (lines 48-50), and to generate the time series of symptom onsets (line 51).
Which line defines the likelihood, and how does it relate to the section about observation uncertainty above?
:::

::: {.callout-note collapse="true"}
## Solution
Line 57 defines the likelihood, and it does so using the Poisson observation uncertainty we used above.
:::

We can now use this model to conduct inference, i.e. to try to reconstruct the time series of infections from the time series of onsets that we generated earlier.

```{r inf_fit}
data <- list(
  n = nrow(onsets),
  obs = onsets$observed,
  ip_shape = 5,
  ip_rate = 1,
  ip_max = 15
)
inf_fit <- mod$sample(
  data = data, refresh = 0, show_exceptions = FALSE, show_messages = FALSE
)
```

::: {.callout-caution}
The arguments to `mod$sample()` after the `data` argument are there to remove the amount printed to the screen (and in this document).
You can remove them and you'll get more messages from the stan sampler (which can be very useful for diagnosing and debugging).
:::


::: {.callout-tip}
In this model, we have estimated many more parameters than in the previous models: instead of e.g. 2 parameters of a probability distribution, we now have a total of `r nrow(onsets)` time points for which we estimate the number of infections. 
This is because we don't have a model for the _process_ that generates infections.
How would this be different if we e.g. used an SIR model here?
:::

We can see the first few estimates of the number of infections using

```{r inf_summary}
inf_fit
```

Again, we can do a posterior predictive check by plotting the estimates of the time series of infections (with uncertainy) against the data.
Does it look like a good fit?

```{r inf_ppc}
# Extract posterior draws
inf_posterior <- inf_fit |>
  gather_draws(infections[day]) |>
  group_by(day) |>
  summarise(
    median = median(.value),
    lower_90 = quantile(.value, 0.05),
    upper_90 = quantile(.value, 0.95),
    .groups = "drop"
  ) |>
  mutate(infection_date = inf_time_series$infection_date)


ggplot(mapping = aes(x = infection_date)) +
  geom_line(data = inf_time_series, mapping = aes(y = n)) +
  geom_ribbon(
    data = inf_posterior,
    mapping = aes(ymin = lower_90, ymax = upper_90), alpha = 0.25, colour = NA
  )
```

::: {.callout-tip}
This time we used the `gather_draws()` function included in `tidybayes` to extract the inference results. 
This is particularly useful when dealing with arrays such as `inference` because it allows to extract them with a given index (here: `[day]`).
:::

# Going further

- Above, we used a Poisson distribution to characterise uncertainty.
In the Poisson distribution, the variance is the same as the mean.
Another common choice is the negative binomial distribution, which has a more flexible relationship between variance and mean.
If you re-did the analysis above with the negative binomail distribution, what would be the difference?

- We could have used the individual-level model of the previous section to try to estimate the number of infections with a known delay distribution by estimating each individual infection time.
How would this look in stan code?
Would you expect it to yield a different result?
